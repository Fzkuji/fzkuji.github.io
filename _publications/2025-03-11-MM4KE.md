---
title: "Model Merging for Knowledge Editing"
collection: publications
category: conferences
permalink: /publication/2025-03-11-MM4KE
excerpt: 'A two-stage framework combining robust supervised fine-tuning with model merging for efficient knowledge editing in LLMs that preserves general capabilities while outperforming existing methods.'
date: 2025-03-11
venue: 'ACLâ€™25(Industry Track), Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics'
paperurl: 'https://arxiv.org/pdf/2406.12529'
citation: >-
  
---

Large Language Models (LLMs) require continuous updates to maintain accurate and current knowledge as the world evolves. While existing knowledge editing approaches offer various solutions for knowledge updating, they often struggle with sequential editing scenarios and harm the general capabilities of the model, thereby significantly hampering their practical applicability.
This paper proposes a two-stage framework combining robust supervised fine-tuning (R-SFT) with model merging for knowledge editing. Our method first fine-tunes the LLM to internalize new knowledge fully, then merges the fine-tuned model with the original foundation model to preserve newly acquired knowledge and general capabilities. 
Experimental results demonstrate that our approach significantly outperforms existing methods in sequential editing while better preserving the original performance of the model, all without requiring any architectural changes. Code is available at [Applied-Machine-Learning-Lab/MM4KE](https://github.com/Applied-Machine-Learning-Lab/MM4KE.git).

