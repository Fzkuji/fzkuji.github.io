---
title: "A Unified Framework for Multi-Domain CTR Prediction via Large Language Models"
collection: publications
category: manuscripts
permalink: /publication/2024-09-24-Uni-CTR
excerpt: 'Uni-CTR leverages Large Language Models and pluggable domain networks to address the seesaw phenomenon and scalability challenges in multi-domain CTR prediction, achieving state-of-the-art performance across various scenarios.'
date: 2024-09-24
venue: 'ACM Transactions on Information Systems (TOIS)'
#slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'https://dl.acm.org/doi/pdf/10.1145/3698878'
citation: 'Zichuan Fu, Xiangyang Li, Chuhan Wu, Yichao Wang, Kuicai Dong, Xiangyu Zhao, Mengchen Zhao, Huifeng Guo, and Ruiming Tang. 2024. A Unified Framework for Multi-Domain CTR Prediction via Large Language Models. ACM Trans. Inf. Syst. Just Accepted (October 2024). <a href="https://doi.org/10.1145/3698878">https://doi.org/10.1145/3698878</a>'
---

Multi-Domain Click-Through Rate (MDCTR) prediction is crucial for online recommendation platforms, which involves providing personalized recommendation services to users in different domains. However, current MDCTR models are confronted with the following limitations. Firstly, due to varying data sparsity in different domains, models can easily be dominated by some specific domains, which leads to significant performance degradation in other domains (i.e., the “seesaw phenomenon”). Secondly, when new domain emerges, the scalability of existing methods is limited, making it difficult to adapt to the dynamic growth of the domain. Traditional MDCTR models usually use one-hot encoding for semantic information such as product titles, thus losing rich semantic information and leading to insufficient generalization of the model. In this paper, we propose a novel solution Uni-CTR to address these challenges. Uni-CTR leverages Large Language Model (LLM) to extract layer-wise semantic representations that capture domain commonalities, mitigating the seesaw phenomenon and enhancing generalization. Besides, it incorporates a pluggable domain-specific network to capture domain characteristics, ensuring scalability to dynamic domain growth. Experimental results on public datasets and industrial scenarios show that Uni-CTR significantly outperforms state-of-the-art (SOTA) models. In addition, Uni-CTR shows significant results in zero shot prediction. Code is available at [Applied-Machine-Learning-Lab
/Uni-CTR](https://github.com/Applied-Machine-Learning-Lab/Uni-CTR.git).